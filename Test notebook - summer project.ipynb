{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import time\n",
    "from tensorflow.python.ops import init_ops\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.python.training.moving_averages import assign_moving_average\n",
    "\n",
    "#set up the neural network\n",
    "def neural_net(x,neurons,is_training, name, mv_decay=0.9,dtype=tf.float32):\n",
    "\n",
    "    #normalise the output using mean and sd of current input. \n",
    "    #more info @1502.03167\n",
    "    \n",
    "    def _batch_normalization(_x):\n",
    "        #initialise offsets\n",
    "        beta = tf.compat.v1.get_variable(\"beta\",[_x.get_shape()[-1]],dtype,init_ops.zeros_initializer())\n",
    "        \n",
    "        #initialise scale\n",
    "        gamma = tf.compat.v1.get_variable(\"gamma\",[_x.get_shape()[-1]],dtype,init_ops.ones_initializer())\n",
    "        \n",
    "        mv_mean = tf.compat.v1.get_variable(\"mv_mean\",[_x.get_shape()[-1]],dtype,init_ops.zeros_initializer(),trainable=False)\n",
    "        \n",
    "        mv_variance = tf.compat.v1.get_variable(\"mv_variance\",[_x.get_shape()[-1]],dtype,init_ops.ones_initializer(),trainable=False)\n",
    "        \n",
    "        #calculate mean and variance from the current output\n",
    "        mean,variance = tf.nn.moments(_x,[0],name=\"moments\")\n",
    "        \n",
    "        tf.compat.v1.add_to_collection(tf.compat.v1.GraphKeys.UPDATE_OPS,assign_moving_average(mv_mean,mean,mv_decay,True))\n",
    "        \n",
    "        tf.compat.v1.add_to_collection(tf.compat.v1.GraphKeys.UPDATE_OPS,assign_moving_average(mv_variance,variance,mv_decay,False))\n",
    "\n",
    "        mean,variance = tf.cond(is_training, \n",
    "                                lambda: (mean,variance),\n",
    "                                lambda: (mv_mean,mv_variance))\n",
    "        return tf.nn.batch_normalization(_x,mean,variance,beta,gamma,1e-6)\n",
    "\n",
    "    #layers of the neural networks and initialise weights\n",
    "    def _layer(_x,out_size,activation_fn):\n",
    "        w = tf.compat.v1.get_variable(\"weights\",[_x.get_shape().as_list()[-1],out_size],\n",
    "                            dtype,\n",
    "                            #aka xavier initialiser - keeps the scale of gradients roughly the same\n",
    "                            initializers.glorot_normal())\n",
    "        return activation_fn(_batch_normalization(tf.matmul(_x,w)))\n",
    "\n",
    "    with tf.compat.v1.variable_scope(name,reuse = tf.compat.v1.AUTO_REUSE):\n",
    "        x = _batch_normalization(x)\n",
    "        for i in range(len(neurons)):\n",
    "            with tf.compat.v1.variable_scope(\"layer_%i_\" % (i+1)):\n",
    "                #taking hyperbolic tan as non-linear activation function\n",
    "                x = _layer(x,neurons[i],\n",
    "                           tf.compat.v1.nn.tanh if i<len(neurons)-1 else tf.identity)\n",
    "    return x\n",
    "\n",
    "def kolmogorov_train_and_test(xi,x_sde,phi,u_reference,neurons,\n",
    "                              lf_boundaries,lr_values,train_steps,\n",
    "                              mc_rounds,mc_freq,file_name,\n",
    "                              dtype=tf.float32):\n",
    "  \n",
    "    def _approximate_errors():\n",
    "        lr,gs = sess.run([learning_rate,global_step])\n",
    "        l1_err,l2_err,li_err = 0. , 0. , 0. \n",
    "        rel_l1_err,rel_l2_err,rel_li_err = 0.,0.,0.\n",
    "        for _ in range(mc_rounds):\n",
    "            l1,l2,li,rl1,rl2,rli \\\n",
    "              =sess.run([err_l_1,err_l_2,err_l_inf,\n",
    "                         rel_err_l_1,rel_err_l_2,rel_err_l_inf],\n",
    "                        feed_dict = {is_training: False})\n",
    "            \n",
    "            #cummulate errors\n",
    "            l1_err,l2_err,li_err = (l1_err + l1, l2_err+l2,np.maximum(li_err,li))\n",
    "            rel_l1_err,rel_l2_err,rel_li_err \\\n",
    "              = (rel_l1_err + rl1,rel_l2_err+rl2,np.maximum(rel_li_err,rli))\n",
    "            l1_err,l2_err = l1_err / mc_rounds, np.sqrt(l2_err/mc_rounds)\n",
    "            rel_l1_err, rel_l2_err \\\n",
    "              = rel_l1_err / mc_rounds, np.sqrt(rel_l2_err/mc_rounds)\n",
    "            t_mc = time.time()\n",
    "            file_out.write(\"%i, %f,%f,%f,%f,%f,%f,%f,%f,%f\\n\" % (gs,l1_err,l2_err,li_err,rel_l1_err,rel_l2_err,rel_li_err,lr,t1_train-t0_train,t_mc-t1_train))\n",
    "            file_out.flush()\n",
    "\n",
    "    t0_train = time.time()\n",
    "    is_training = tf.compat.v1.placeholder(tf.bool,[])\n",
    "\n",
    "    with tf.compat.v1.variable_scope(tf.compat.v1.get_variable_scope(),reuse=tf.compat.v1.AUTO_REUSE): \n",
    "        \n",
    "        #run through the trained neural network\n",
    "        u_approx = neural_net(xi,neurons,is_training,\"u_approx\",dtype = dtype)\n",
    "        \n",
    "        #compare with calculated value\n",
    "        loss = tf.reduce_mean(tf.compat.v1.squared_difference(u_approx,phi(x_sde)))\n",
    "\n",
    "        #compare nn approx value with mc values and calculate all errs\n",
    "        err = tf.compat.v1.abs(u_approx - u_reference)\n",
    "        err_l_1 = tf.compat.v1.reduce_mean(err)\n",
    "        err_l_2 = tf.compat.v1.reduce_mean(err ** 2)\n",
    "        err_l_inf = tf.compat.v1.reduce_max(err)\n",
    "        \n",
    "        #relative errors \n",
    "        rel_err = err/ tf.compat.v1.maximum(u_reference,1e-8)\n",
    "        rel_err_l_1 = tf.compat.v1.reduce_mean(rel_err)\n",
    "        rel_err_l_2 = tf.compat.v1.reduce_mean(rel_err ** 2)\n",
    "        rel_err_l_inf = tf.compat.v1.reduce_max(rel_err)\n",
    "\n",
    "        #\n",
    "        global_step = tf.compat.v1.get_variable(\"global_step\",[], tf.int32,\n",
    "                                      tf.compat.v1.constant_initializer(),\n",
    "                                      trainable = False)\n",
    "        \n",
    "        #\n",
    "        learning_rate = tf.compat.v1.train.piecewise_constant(global_step,\n",
    "                                                    lr_boundaries,\n",
    "                                                    lr_values)\n",
    "        \n",
    "        \n",
    "        optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate)\n",
    "        update_ops = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.UPDATE_OPS,\"u_appox\")\n",
    "        \n",
    "\n",
    "        with tf.compat.v1.control_dependencies(update_ops):\n",
    "            #minimise the loss take the gradient\n",
    "            train_op = optimizer.minimize(loss, global_step)\n",
    "\n",
    "        file_out = open(file_name,\"w\")\n",
    "        file_out.write(\"step,l1_err,l2_err,li_err,l1_rel,l2_rel,li_rel,learning_rate,time_train,time_mc\\n\")\n",
    "\n",
    "        #record errors at each step \n",
    "        with tf.compat.v1.Session() as sess:\n",
    "            sess.run(tf.compat.v1.global_variables_initializer())\n",
    "\n",
    "            for step in range(train_steps):\n",
    "                if step % mc_freq == 0:\n",
    "                    t1_train = time.time()\n",
    "                    _approximate_errors()\n",
    "                    t0_train = time.time()\n",
    "                \n",
    "                sess.run(train_op,feed_dict = {is_training: True})\n",
    "\n",
    "            t1_train = time.time()\n",
    "            _approximate_errors()\n",
    "        \n",
    "        file_out.close()\n",
    "        #file_out.save(file_name)\n",
    "        #files.download(file_name)\n",
    "    return file_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#geometric BM \n",
    "tf.compat.v1.reset_default_graph()\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "tf.compat.v1.get_variable_scope().reuse_variables()\n",
    "\n",
    "dtype = \"float32\"\n",
    "T,N,d = 1.,1,10\n",
    "r,c,K = 0.05,0.1,100.\n",
    "mu = -0.05\n",
    "sigma = tf.constant(0.1 + 0.5 * np.linspace(start=1./d,stop = 1.,num = d,endpoint = True,dtype = dtype))\n",
    "batch_size = 500\n",
    "neurons = [d+10,d+10,1]\n",
    "train_steps = 30000\n",
    "mc_rounds, mc_freq = 1,250\n",
    "mc_samples_ref,mc_rounds_ref = 1000,1000\n",
    "lr_boundaries = [10000,20000]\n",
    "lr_values = [0.001,0.0001,0.00001]\n",
    "\n",
    "#random starting points\n",
    "xi = tf.random.uniform((batch_size,d),minval=90.,maxval=110.,dtype=dtype)\n",
    "\n",
    "#u(0,x)\n",
    "def phi(x,axis=1):\n",
    "    return np.exp(-r*T) * tf.maximum(tf.reduce_max(x,axis=axis,keepdims=True)-K,0.)\n",
    "\n",
    "def mc_body(idx,p):\n",
    "    #actual stochastic diff equation for MC method\n",
    "    #exact solution of a black scholes with gbm. \n",
    "    _x = xi * tf.exp((mu-0.5*sigma**2)*T + sigma *tf.random.normal((mc_samples_ref,batch_size,d),stddev=np.sqrt(T/N),dtype=dtype))\n",
    "    return idx + 1, p+tf.reduce_mean(phi(_x,2),axis=0)\n",
    "\n",
    "#the actual equation for solving\n",
    "#used in training\n",
    "x_sde = xi * tf.exp((r-c-0.5*sigma**2)*T +sigma*tf.random.normal((batch_size,d),stddev=np.sqrt(T/N),dtype=dtype))\n",
    "\n",
    "#while index less than mc rounds ref, calculate mc value, else 0. \n",
    "_,u = tf.compat.v1.while_loop(lambda idx,p: idx<mc_rounds_ref, mc_body,(tf.constant(0),tf.zeros((batch_size,1),dtype)))\n",
    "\n",
    "#find the comparison mc values\n",
    "u_reference = u / tf.cast(mc_rounds_ref,dtype)\n",
    "\n",
    "file_output = kolmogorov_train_and_test(xi,x_sde,phi,u_reference,neurons,lr_boundaries,lr_values,train_steps,mc_rounds,mc_freq,\"GBM_test.csv\",dtype)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(\"GBM_test.csv\")\n",
    "df = pd.DataFrame(data)\n",
    "df.set_index(\"step\",inplace =True)\n",
    "\n",
    "plt.plot(df.index,df.l1_rel,color=\"red\",label =\"l1 rel\")\n",
    "\n",
    "plt.plot(df.index,df.l2_rel,color=\"blue\",label =\"l2 rel\")\n",
    "\n",
    "plt.plot(df.index,df.li_rel,color=\"green\",label =\"li rel\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l1_err</th>\n",
       "      <th>l2_err</th>\n",
       "      <th>li_err</th>\n",
       "      <th>l1_rel</th>\n",
       "      <th>l2_rel</th>\n",
       "      <th>li_rel</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>time_train</th>\n",
       "      <th>time_mc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>step</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66.651733</td>\n",
       "      <td>66.725263</td>\n",
       "      <td>76.422554</td>\n",
       "      <td>1.001230</td>\n",
       "      <td>1.001233</td>\n",
       "      <td>1.006573</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.835946</td>\n",
       "      <td>97.182954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>64.582672</td>\n",
       "      <td>64.673074</td>\n",
       "      <td>73.031364</td>\n",
       "      <td>0.970878</td>\n",
       "      <td>0.970879</td>\n",
       "      <td>0.975259</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.334665</td>\n",
       "      <td>96.986524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>63.897743</td>\n",
       "      <td>63.979098</td>\n",
       "      <td>72.070335</td>\n",
       "      <td>0.960752</td>\n",
       "      <td>0.960754</td>\n",
       "      <td>0.965445</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.801552</td>\n",
       "      <td>96.705263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>63.308434</td>\n",
       "      <td>63.392125</td>\n",
       "      <td>71.464912</td>\n",
       "      <td>0.950624</td>\n",
       "      <td>0.950628</td>\n",
       "      <td>0.956686</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.875646</td>\n",
       "      <td>96.581293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>62.037601</td>\n",
       "      <td>62.123104</td>\n",
       "      <td>71.244408</td>\n",
       "      <td>0.933690</td>\n",
       "      <td>0.933696</td>\n",
       "      <td>0.943261</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.811380</td>\n",
       "      <td>96.458339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>61.249344</td>\n",
       "      <td>61.340435</td>\n",
       "      <td>69.523674</td>\n",
       "      <td>0.923000</td>\n",
       "      <td>0.923017</td>\n",
       "      <td>0.933270</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.775654</td>\n",
       "      <td>96.758604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>59.795147</td>\n",
       "      <td>59.884724</td>\n",
       "      <td>68.393295</td>\n",
       "      <td>0.900872</td>\n",
       "      <td>0.900906</td>\n",
       "      <td>0.918368</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.812913</td>\n",
       "      <td>96.619061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750</th>\n",
       "      <td>58.479347</td>\n",
       "      <td>58.576406</td>\n",
       "      <td>66.897987</td>\n",
       "      <td>0.878306</td>\n",
       "      <td>0.878329</td>\n",
       "      <td>0.892310</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.789784</td>\n",
       "      <td>97.578598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>57.297070</td>\n",
       "      <td>57.385226</td>\n",
       "      <td>66.545082</td>\n",
       "      <td>0.865608</td>\n",
       "      <td>0.865636</td>\n",
       "      <td>0.882574</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.755219</td>\n",
       "      <td>99.824707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2250</th>\n",
       "      <td>56.291924</td>\n",
       "      <td>56.381034</td>\n",
       "      <td>65.593658</td>\n",
       "      <td>0.847574</td>\n",
       "      <td>0.847614</td>\n",
       "      <td>0.868263</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.778304</td>\n",
       "      <td>98.519393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2500</th>\n",
       "      <td>54.991188</td>\n",
       "      <td>55.092549</td>\n",
       "      <td>64.080383</td>\n",
       "      <td>0.831606</td>\n",
       "      <td>0.831662</td>\n",
       "      <td>0.854450</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.806641</td>\n",
       "      <td>98.189057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2750</th>\n",
       "      <td>54.289253</td>\n",
       "      <td>54.386067</td>\n",
       "      <td>62.821804</td>\n",
       "      <td>0.817852</td>\n",
       "      <td>0.817913</td>\n",
       "      <td>0.842541</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.591681</td>\n",
       "      <td>96.518216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>53.818085</td>\n",
       "      <td>53.917632</td>\n",
       "      <td>61.821884</td>\n",
       "      <td>0.809972</td>\n",
       "      <td>0.810049</td>\n",
       "      <td>0.835543</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.797307</td>\n",
       "      <td>95.121355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3250</th>\n",
       "      <td>52.733078</td>\n",
       "      <td>52.846383</td>\n",
       "      <td>62.306896</td>\n",
       "      <td>0.794551</td>\n",
       "      <td>0.794625</td>\n",
       "      <td>0.820630</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.843314</td>\n",
       "      <td>96.276227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3500</th>\n",
       "      <td>51.992771</td>\n",
       "      <td>52.090987</td>\n",
       "      <td>60.741425</td>\n",
       "      <td>0.785773</td>\n",
       "      <td>0.785849</td>\n",
       "      <td>0.816601</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.848325</td>\n",
       "      <td>97.608104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3750</th>\n",
       "      <td>51.430603</td>\n",
       "      <td>51.534590</td>\n",
       "      <td>59.601562</td>\n",
       "      <td>0.776204</td>\n",
       "      <td>0.776291</td>\n",
       "      <td>0.800699</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.823066</td>\n",
       "      <td>89.875300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000</th>\n",
       "      <td>51.033928</td>\n",
       "      <td>51.138560</td>\n",
       "      <td>60.992363</td>\n",
       "      <td>0.767427</td>\n",
       "      <td>0.767513</td>\n",
       "      <td>0.798192</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.726259</td>\n",
       "      <td>87.499995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4250</th>\n",
       "      <td>50.392864</td>\n",
       "      <td>50.494658</td>\n",
       "      <td>60.000252</td>\n",
       "      <td>0.759282</td>\n",
       "      <td>0.759372</td>\n",
       "      <td>0.790232</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.756970</td>\n",
       "      <td>94.155205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4500</th>\n",
       "      <td>50.069725</td>\n",
       "      <td>50.174352</td>\n",
       "      <td>59.113205</td>\n",
       "      <td>0.756138</td>\n",
       "      <td>0.756233</td>\n",
       "      <td>0.785741</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.768266</td>\n",
       "      <td>95.324552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4750</th>\n",
       "      <td>49.483593</td>\n",
       "      <td>49.587554</td>\n",
       "      <td>58.259537</td>\n",
       "      <td>0.745613</td>\n",
       "      <td>0.745719</td>\n",
       "      <td>0.775868</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.748195</td>\n",
       "      <td>95.952032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>48.988247</td>\n",
       "      <td>49.088523</td>\n",
       "      <td>56.667717</td>\n",
       "      <td>0.737448</td>\n",
       "      <td>0.737554</td>\n",
       "      <td>0.765203</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.761730</td>\n",
       "      <td>96.802851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5250</th>\n",
       "      <td>48.739349</td>\n",
       "      <td>48.837179</td>\n",
       "      <td>58.317345</td>\n",
       "      <td>0.733680</td>\n",
       "      <td>0.733787</td>\n",
       "      <td>0.767771</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.836746</td>\n",
       "      <td>96.630396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5500</th>\n",
       "      <td>48.757351</td>\n",
       "      <td>48.874073</td>\n",
       "      <td>57.248783</td>\n",
       "      <td>0.732040</td>\n",
       "      <td>0.732169</td>\n",
       "      <td>0.762982</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.805817</td>\n",
       "      <td>96.745771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5750</th>\n",
       "      <td>47.944805</td>\n",
       "      <td>48.059272</td>\n",
       "      <td>57.838776</td>\n",
       "      <td>0.722888</td>\n",
       "      <td>0.723023</td>\n",
       "      <td>0.759497</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.806053</td>\n",
       "      <td>96.161011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6000</th>\n",
       "      <td>47.387672</td>\n",
       "      <td>47.506797</td>\n",
       "      <td>56.192841</td>\n",
       "      <td>0.712591</td>\n",
       "      <td>0.712743</td>\n",
       "      <td>0.746883</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.859194</td>\n",
       "      <td>96.391889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6250</th>\n",
       "      <td>46.980686</td>\n",
       "      <td>47.096726</td>\n",
       "      <td>56.135376</td>\n",
       "      <td>0.705249</td>\n",
       "      <td>0.705402</td>\n",
       "      <td>0.741534</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.832553</td>\n",
       "      <td>96.784573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6500</th>\n",
       "      <td>46.373859</td>\n",
       "      <td>46.492602</td>\n",
       "      <td>56.244743</td>\n",
       "      <td>0.699408</td>\n",
       "      <td>0.699576</td>\n",
       "      <td>0.739063</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.814026</td>\n",
       "      <td>96.600406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6750</th>\n",
       "      <td>46.216663</td>\n",
       "      <td>46.342875</td>\n",
       "      <td>56.017479</td>\n",
       "      <td>0.695266</td>\n",
       "      <td>0.695448</td>\n",
       "      <td>0.735175</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.813145</td>\n",
       "      <td>97.545986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7000</th>\n",
       "      <td>45.664124</td>\n",
       "      <td>45.792538</td>\n",
       "      <td>55.728092</td>\n",
       "      <td>0.689396</td>\n",
       "      <td>0.689586</td>\n",
       "      <td>0.731132</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.777468</td>\n",
       "      <td>95.926379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         l1_err     l2_err     li_err    l1_rel    l2_rel    li_rel  \\\n",
       "step                                                                  \n",
       "0     66.651733  66.725263  76.422554  1.001230  1.001233  1.006573   \n",
       "250   64.582672  64.673074  73.031364  0.970878  0.970879  0.975259   \n",
       "500   63.897743  63.979098  72.070335  0.960752  0.960754  0.965445   \n",
       "750   63.308434  63.392125  71.464912  0.950624  0.950628  0.956686   \n",
       "1000  62.037601  62.123104  71.244408  0.933690  0.933696  0.943261   \n",
       "1250  61.249344  61.340435  69.523674  0.923000  0.923017  0.933270   \n",
       "1500  59.795147  59.884724  68.393295  0.900872  0.900906  0.918368   \n",
       "1750  58.479347  58.576406  66.897987  0.878306  0.878329  0.892310   \n",
       "2000  57.297070  57.385226  66.545082  0.865608  0.865636  0.882574   \n",
       "2250  56.291924  56.381034  65.593658  0.847574  0.847614  0.868263   \n",
       "2500  54.991188  55.092549  64.080383  0.831606  0.831662  0.854450   \n",
       "2750  54.289253  54.386067  62.821804  0.817852  0.817913  0.842541   \n",
       "3000  53.818085  53.917632  61.821884  0.809972  0.810049  0.835543   \n",
       "3250  52.733078  52.846383  62.306896  0.794551  0.794625  0.820630   \n",
       "3500  51.992771  52.090987  60.741425  0.785773  0.785849  0.816601   \n",
       "3750  51.430603  51.534590  59.601562  0.776204  0.776291  0.800699   \n",
       "4000  51.033928  51.138560  60.992363  0.767427  0.767513  0.798192   \n",
       "4250  50.392864  50.494658  60.000252  0.759282  0.759372  0.790232   \n",
       "4500  50.069725  50.174352  59.113205  0.756138  0.756233  0.785741   \n",
       "4750  49.483593  49.587554  58.259537  0.745613  0.745719  0.775868   \n",
       "5000  48.988247  49.088523  56.667717  0.737448  0.737554  0.765203   \n",
       "5250  48.739349  48.837179  58.317345  0.733680  0.733787  0.767771   \n",
       "5500  48.757351  48.874073  57.248783  0.732040  0.732169  0.762982   \n",
       "5750  47.944805  48.059272  57.838776  0.722888  0.723023  0.759497   \n",
       "6000  47.387672  47.506797  56.192841  0.712591  0.712743  0.746883   \n",
       "6250  46.980686  47.096726  56.135376  0.705249  0.705402  0.741534   \n",
       "6500  46.373859  46.492602  56.244743  0.699408  0.699576  0.739063   \n",
       "6750  46.216663  46.342875  56.017479  0.695266  0.695448  0.735175   \n",
       "7000  45.664124  45.792538  55.728092  0.689396  0.689586  0.731132   \n",
       "\n",
       "      learning_rate  time_train    time_mc  \n",
       "step                                        \n",
       "0             0.001    1.835946  97.182954  \n",
       "250           0.001    1.334665  96.986524  \n",
       "500           0.001    0.801552  96.705263  \n",
       "750           0.001    0.875646  96.581293  \n",
       "1000          0.001    0.811380  96.458339  \n",
       "1250          0.001    0.775654  96.758604  \n",
       "1500          0.001    0.812913  96.619061  \n",
       "1750          0.001    0.789784  97.578598  \n",
       "2000          0.001    0.755219  99.824707  \n",
       "2250          0.001    0.778304  98.519393  \n",
       "2500          0.001    0.806641  98.189057  \n",
       "2750          0.001    0.591681  96.518216  \n",
       "3000          0.001    0.797307  95.121355  \n",
       "3250          0.001    0.843314  96.276227  \n",
       "3500          0.001    0.848325  97.608104  \n",
       "3750          0.001    0.823066  89.875300  \n",
       "4000          0.001    0.726259  87.499995  \n",
       "4250          0.001    0.756970  94.155205  \n",
       "4500          0.001    0.768266  95.324552  \n",
       "4750          0.001    0.748195  95.952032  \n",
       "5000          0.001    0.761730  96.802851  \n",
       "5250          0.001    0.836746  96.630396  \n",
       "5500          0.001    0.805817  96.745771  \n",
       "5750          0.001    0.806053  96.161011  \n",
       "6000          0.001    0.859194  96.391889  \n",
       "6250          0.001    0.832553  96.784573  \n",
       "6500          0.001    0.814026  96.600406  \n",
       "6750          0.001    0.813145  97.545986  \n",
       "7000          0.001    0.777468  95.926379  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
